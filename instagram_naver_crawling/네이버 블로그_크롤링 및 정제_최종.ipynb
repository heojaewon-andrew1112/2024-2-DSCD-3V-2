{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b17bcf-9e06-4fc8-b95c-736f54aa956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " '파리맛집_네이버_최종.csv' 파일로 저장 완료.\n",
      " '파리관광_네이버_최종.csv' 파일로 저장 완료.\n",
      " '파리핫플_네이버_최종.csv' 파일로 저장 완료.\n",
      " '파리숙소_네이버_최종.csv' 파일로 저장 완료.\n",
      " '파리쇼핑_네이버_최종.csv' 파일로 저장 완료.\n",
      " '파리여행_네이버_최종.csv' 파일로 저장 완료.\n",
      " '오사카맛집_네이버_최종.csv' 파일로 저장 완료.\n",
      " '오사카관광_네이버_최종.csv' 파일로 저장 완료.\n",
      " '오사카핫플_네이버_최종.csv' 파일로 저장 완료.\n",
      " '오사카숙소_네이버_최종.csv' 파일로 저장 완료.\n",
      " '오사카쇼핑_네이버_최종.csv' 파일로 저장 완료.\n",
      " '오사카여행_네이버_최종.csv' 파일로 저장 완료.\n",
      " '방콕맛집_네이버_최종.csv' 파일로 저장 완료.\n",
      " '방콕관광_네이버_최종.csv' 파일로 저장 완료.\n",
      " '방콕핫플_네이버_최종.csv' 파일로 저장 완료.\n",
      " '방콕숙소_네이버_최종.csv' 파일로 저장 완료.\n",
      " '방콕쇼핑_네이버_최종.csv' 파일로 저장 완료.\n",
      " '방콕여행_네이버_최종.csv' 파일로 저장 완료.\n",
      " '뉴욕맛집_네이버_최종.csv' 파일로 저장 완료.\n",
      " '뉴욕관광_네이버_최종.csv' 파일로 저장 완료.\n",
      " '뉴욕핫플_네이버_최종.csv' 파일로 저장 완료.\n",
      " '뉴욕숙소_네이버_최종.csv' 파일로 저장 완료.\n",
      " '뉴욕쇼핑_네이버_최종.csv' 파일로 저장 완료.\n",
      " '뉴욕여행_네이버_최종.csv' 파일로 저장 완료.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 불러올 파일들의 공통 부분과 도시 목록 정의\n",
    "cities = ['파리', '오사카', '방콕', '뉴욕']\n",
    "categories = ['맛집', '관광', '핫플', '숙소', '쇼핑', '여행']\n",
    "\n",
    "def getresult(client_id, client_secret, query, display=10, start=1, sort='sim'):\n",
    "    encText = urllib.parse.quote(query)\n",
    "    url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText + \\\n",
    "          \"&display=\" + str(display) + \"&start=\" + str(start) + \"&sort=\" + sort\n",
    "\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\", client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\", client_secret)\n",
    "    try:\n",
    "        response = urllib.request.urlopen(request)\n",
    "        rescode = response.getcode()\n",
    "        if rescode == 200:\n",
    "            response_body = response.read()\n",
    "            response_json = json.loads(response_body)\n",
    "            return pd.DataFrame(response_json['items'])\n",
    "        else:\n",
    "            print(\"Error Code:\" + rescode)\n",
    "            return pd.DataFrame()  # 빈 데이터프레임 반환\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(f\"HTTP Error: {e.code} - {e.reason}\")\n",
    "        return pd.DataFrame()\n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"URL Error: {e.reason}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# HTML 태그(<b>)와 이모티콘, 특수문자 등을 제거하는 함수\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # HTML 태그 제거\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        # 이모티콘 및 특수 기호 제거 (한글, 영어, 숫자, 공백 제외)\n",
    "        text = re.sub(r'[^\\w\\s가-힣]', '', text)\n",
    "    return text\n",
    "\n",
    " # 조사나 접속사, 이모티콘 등을 제거하는 함수\n",
    "def clean_korean_text(text):\n",
    "    if pd.isna(text):  # NaN 값일 경우 빈 문자열로 처리\n",
    "        return ''\n",
    "    \n",
    "    # 2. 형태소 분석 후 조사, 접속사 제거\n",
    "    morphs = okt.pos(text, norm=True, stem=True)\n",
    "    \n",
    "    # 3. 조사와 접속사 필터링 (조사(Josa), 접속사(Conjunction) 태그 제외)\n",
    "    cleaned_text = ' '.join(word for word, tag in morphs if tag not in ['Josa', 'Conjunction', 'Adjective', 'Adverb', 'Eomi', 'Determiner', 'Exclamation', 'Suffix', 'Verb', 'KoreanParticle'])   \n",
    "\n",
    "    return cleaned_text\n",
    "    \n",
    "# 청킹 함수: 명사(Noun), 형용사(Adjective) 등을 추출해 묶는 방식\n",
    "def chunk_korean_text(text):\n",
    "    if pd.isnull(text):  # text가 None인 경우 빈 문자열로 처리\n",
    "        return \"\"\n",
    "    \n",
    "    english_words = re.findall(r'[a-zA-Z]+', text)\n",
    "    \n",
    "    morphs = okt.pos(text, norm=True, stem=True)\n",
    "    \n",
    "    filtered_words = [word for word, pos in morphs if pos in ['Noun', 'Alpha']]  # 명사와 영어 단어만 남김\n",
    "    \n",
    "    # 영어 단어 다시 추가\n",
    "    filtered_words.extend(english_words)\n",
    "    \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "client_id = \"내꺼\"\n",
    "client_secret = \"내꺼\"\n",
    "\n",
    "# 모든 도시와 카테고리 파일을 한꺼번에 불러오는 코드\n",
    "for city in cities:\n",
    "    for category in categories:\n",
    "        query = f'{city}{category}' ## 키워드 설정\n",
    "        display = 100  # 최대값\n",
    "        sort_options = ['sim', 'date']\n",
    "        \n",
    "        result_all = pd.DataFrame()\n",
    "        total_results_per_sort = 1000  # 각 정렬 옵션 당 최대 1000개\n",
    "        \n",
    "        for sort in sort_options:\n",
    "            for start in range(1, total_results_per_sort + 1, display):\n",
    "                result = getresult(client_id, client_secret, query, display, start, sort)\n",
    "                if not result.empty:\n",
    "                    result_all = pd.concat([result_all, result], ignore_index=True)\n",
    "                time.sleep(1)  # API 호출 간 딜레이 추가 (1초)\n",
    "\n",
    "        # 기존 데이터프레임에서 title, description 컬럼만 선택하고 새로운 데이터프레임으로 만듦\n",
    "        result = result_all[['title', 'description', 'postdate']].copy()\n",
    "        \n",
    "        # title과 description에서 HTML 태그 및 특수문자 제거\n",
    "        result['title'] = result['title'].apply(clean_text)\n",
    "        result['description'] = result['description'].apply(clean_text)\n",
    "        \n",
    "        # Konlpy의 Okt 객체 생성\n",
    "        okt = Okt()\n",
    "\n",
    "        # 1. content 컬럼에서 조사, 접속사, 이모티콘 제거 적용\n",
    "        result['cleaned_description'] = result['description'].apply(lambda x: clean_korean_text(x))\n",
    "        \n",
    "        # 2. 조사, 접속사 제거된 텍스트에서 청킹 적용 (명사, 형용사, 동사만 남김)\n",
    "        result['chunked_description'] = result['cleaned_description'].apply(lambda x: chunk_korean_text(x))\n",
    "\n",
    "        # 3. CSV 파일로 저장\n",
    "        output_file = f'{city}{category}_네이버_최종.csv'\n",
    "        result[['title', 'chunked_description', 'postdate']].to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        print(f\" '{output_file}' 파일로 저장 완료.\")        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
